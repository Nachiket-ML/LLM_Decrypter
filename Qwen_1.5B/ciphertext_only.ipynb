{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90616e-e411-4e1c-ab46-fba50feab559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3720d-76df-4de5-8835-ffff5bb9d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"default.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76183bfd-5ea5-4708-8bd6-055024375d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_data = data[['cipher_text','algorithm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1872b-5376-4424-8ba0-6a18cb60dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced = []\n",
    "for text in shortened_data['cipher_text']:\n",
    "    spaced.append(\" \".join(list(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3caaf6-371e-4d36-ad3b-fe582b60b537",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1ff0c-4a9b-4287-8ffc-47705d9f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_data['spaced'] = spaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc396235-95ed-4cd0-a37d-a6f980c68b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_data.iloc[0]['spaced']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e0215-040a-4638-aad2-86701cf54a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" \n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-1.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2fcbb-b8e2-4604-a854-c478a486ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(ciphertext, space_delimeter):\n",
    "    if space_delimeter:\n",
    "        prompt = f\"Ciphertext with space delimeters between characters: '{ciphertext}'\\n\"\n",
    "    else:\n",
    "        prompt = f\"Ciphertext: '{ciphertext}'\\n\"\n",
    "\n",
    "    prompt += \"Identify which encryption method from the allowed list was used.\" \n",
    "    system_prompt = 'You are an expert assistant that identifies encryption methods given ciphertext.\\n'\n",
    "    system_prompt += 'Respond with ONLY one of these labels and nothing else:\\n'\n",
    "    system_prompt += 'Caesar, Atbash, Morse Code, Bacon, Rail Fence, Vigenere, Playfair, RSA, AES.'\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        attention_mask=model_inputs.attention_mask,\n",
    "        max_new_tokens=100\n",
    "    )\n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ccec0-2c57-433d-9b4a-e6d2eb06a99f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(shortened_data)):\n",
    "    cipher_text = shortened_data.iloc[i]['cipher_text']\n",
    "    algorithm = shortened_data.iloc[i]['algorithm']  \n",
    "    ground_truth.append(algorithm)\n",
    "    response = generate_response(cipher_text,False)\n",
    "    predicted.append(response)\n",
    "    print(i,response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0a46e-5f47-4f3b-95c5-0babf1b74cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875b6ad-3b60-400e-8b39-1c1c976a0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "to_json = dict()\n",
    "\n",
    "for i in range(len(ground_truth)):\n",
    "    to_json[i] = {'ground_truth': ground_truth[i], 'predicted': predicted[i]}\n",
    "\n",
    "with open(\"cipher_only_no_space.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(to_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d42ea-48cb-4539-86ff-21466d278bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d6f36-5861-47e1-a0dd-613b2c381395",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flush():\n",
    "    import torch\n",
    "    import gc \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018cd153-6a02-4354-8b0f-6bb1e1c961cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with space delimiter\n",
    "\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(shortened_data)):\n",
    "    cipher_text = shortened_data.iloc[i]['spaced']\n",
    "    algorithm = shortened_data.iloc[i]['algorithm']  \n",
    "    ground_truth.append(algorithm)\n",
    "    response = generate_response(cipher_text, True)\n",
    "    predicted.append(response)\n",
    "    print(i,response)\n",
    "\n",
    "    if i%500 == 0:\n",
    "        flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b72d0-8924-4697-b02c-e700b4f9f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "to_json = dict()\n",
    "\n",
    "for i in range(len(ground_truth)):\n",
    "    to_json[i] = {'ground_truth': ground_truth[i], 'predicted': predicted[i]}\n",
    "\n",
    "with open(\"cipher_only_with_space.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(to_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52773c6-e6a1-48ec-8c81-30a342fae5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5296e10-fadb-4481-a064-33b1b3fcc124",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51a4064-a086-4097-a883-2169a84d2304",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
