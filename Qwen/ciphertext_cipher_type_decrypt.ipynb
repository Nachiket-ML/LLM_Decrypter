{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b90616e-e411-4e1c-ab46-fba50feab559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb3720d-76df-4de5-8835-ffff5bb9d219",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(\"default.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad21b62-2668-4cbf-926d-61f3348e7e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76183bfd-5ea5-4708-8bd6-055024375d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_data = data[['cipher_text','algorithm','plain_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d1872b-5376-4424-8ba0-6a18cb60dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_cipher = []\n",
    "for text in shortened_data['cipher_text']:\n",
    "    spaced_cipher.append(\" \".join(text))\n",
    "\n",
    "spaced_plain = []\n",
    "for text in shortened_data['plain_text']:\n",
    "    spaced_plain.append(\" \".join(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc1ff0c-4a9b-4287-8ffc-47705d9f49d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_data['spaced_cipher'] = spaced_cipher\n",
    "shortened_data['spaced_plain'] = spaced_plain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc396235-95ed-4cd0-a37d-a6f980c68b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shortened_data.iloc[0]['spaced_cipher']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e0215-040a-4638-aad2-86701cf54a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "device = \"cuda\" # the device to load the model onto\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"Qwen/Qwen2-1.5B-Instruct\",\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2-1.5B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d2fcbb-b8e2-4604-a854-c478a486ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(ciphertext,method):\n",
    "    prompt = f\"Given the ciphertext: '{ciphertext}' and the encryption method '{method}', \"\n",
    "    prompt += f'decrypt the ciphertext and respond with the plaintext. Do not respond with text other than the decrypted plain text. Only output the [decoded message] The plaintext is [decoded message]'\n",
    "    system_prompt = 'You are a helpful assistant that decrypts ciphertext given the encryption method. Respond only with the plaintext and nothing else. Do not respond with text other than the decrypted plain text. Only output the [decoded message]'\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "\n",
    "    \n",
    "    model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
    "\n",
    "    generated_ids = model.generate(\n",
    "        model_inputs.input_ids,\n",
    "        attention_mask=model_inputs.attention_mask,\n",
    "        max_new_tokens=200\n",
    "    )\n",
    "    \n",
    "    generated_ids = [\n",
    "        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "    ]\n",
    "    \n",
    "    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f6c480-e2d9-49e3-9ed5-4aa9871f88c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13d03b-77a0-4802-8103-b60dae74ebc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4efc89-66da-4827-b2d4-2ed7dccb56ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc08af1-677c-44ef-953c-1955d181b089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ccec0-2c57-433d-9b4a-e6d2eb06a99f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(shortened_data)):\n",
    "    cipher_text = shortened_data.iloc[i]['cipher_text']\n",
    "    plain_text = shortened_data.iloc[i]['plain_text']\n",
    "    algorithm = shortened_data.iloc[i]['algorithm']  \n",
    "    ground_truth.append(plain_text)\n",
    "    response = generate_response(cipher_text,algorithm)\n",
    "    predicted.append(response)\n",
    "    print(i,response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa0a46e-5f47-4f3b-95c5-0babf1b74cc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2875b6ad-3b60-400e-8b39-1c1c976a0de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "to_json = dict()\n",
    "\n",
    "for i in range(len(ground_truth)):\n",
    "    to_json[i] = {'ground_truth': ground_truth[i], 'predicted': predicted[i]}\n",
    "\n",
    "with open(\"cipher_method_no_space_p2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(to_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12d42ea-48cb-4539-86ff-21466d278bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6c5f29-9418-47ff-bf4c-dbbe7699f67c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24312f6b-ee37-4f0a-908b-a152d650c48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a530b18-21e8-4502-93cd-603a1a351707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efebcbd-60da-4e21-a662-135d59adc4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5d6f36-5861-47e1-a0dd-613b2c381395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018cd153-6a02-4354-8b0f-6bb1e1c961cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with space delimiter\n",
    "\n",
    "ground_truth = []\n",
    "predicted = []\n",
    "for i in range(len(shortened_data)):\n",
    "    cipher_text = shortened_data.iloc[i]['spaced_cipher']\n",
    "    plain_text = shortened_data.iloc[i]['plain_text']\n",
    "    algorithm = shortened_data.iloc[i]['algorithm']  \n",
    "    ground_truth.append(plain_text)\n",
    "    response = generate_response(cipher_text,algorithm)\n",
    "    predicted.append(response)\n",
    "    print(i,response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622b72d0-8924-4697-b02c-e700b4f9f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "to_json = dict()\n",
    "\n",
    "for i in range(len(ground_truth)):\n",
    "    to_json[i] = {'ground_truth': ground_truth[i], 'predicted': predicted[i]}\n",
    "\n",
    "with open(\"cipher_method_with_space_p2.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(to_json, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52773c6-e6a1-48ec-8c81-30a342fae5eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
